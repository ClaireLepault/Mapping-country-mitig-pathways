{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from nltk.tokenize import word_tokenize\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download processed abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4691 preprocessed abstracts\n"
     ]
    }
   ],
   "source": [
    "abstracts_prepro = pd.read_csv(\"./interm/processed_abstracts.csv\")\n",
    "print( \"%d preprocessed abstracts\" % (len(abstracts_prepro)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a Word Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To select the combination (*k*,$\\alpha$,$l_1$), here we will use a *topic coherence* measure called TC-W2V. This measure relies on the use of a *word embedding* model constructed from our corpus. So in this step we will use the *Gensim* implementation of Word2Vec to build a Word2Vec model based on our collection of abstracts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to define a class that will generate documents in a form that can be consumed by Gensim's Word2Vec implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_word2vec(data_samples):\n",
    "    liste_mots_abstracts =[]\n",
    "    for k in range(len(data_samples)):\n",
    "            tokens = word_tokenize(str(data_samples[k]))\n",
    "            liste_mots_abstracts.append(tokens)\n",
    "    return(liste_mots_abstracts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fit = list_word2vec(abstracts_prepro['abstracts_prepro'].to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now build a Skipgram Word2Vec model from all documents in the input file using *Gensim*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myhash(obj):\n",
    "    return hash(obj) % (2 ** 32)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the model has 500 dimensions, the minimum document-term frequency is 47 (1% as for tf-idf selection)\n",
    "w2v_model = Word2Vec(data_fit, size=500, min_count=47, workers=1, seed = 1511, hashfxn = myhash)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2vec has more terms than the TF-IDF as it does not exclude words that are too frequent (i.e., that appear in more than 95$\\%$ of the abstracts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model has 1533 terms\n"
     ]
    }
   ],
   "source": [
    "print( \"Model has %d terms\" % len(w2v_model.wv.vocab) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save trained word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = w2v_model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors.save(\"./interm/word2vec.wordvectors\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
