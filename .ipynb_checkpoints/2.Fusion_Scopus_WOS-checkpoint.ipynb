{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3811 X 10  WOS dataframe\n",
      "Loaded 4129 X 9  Scopus dataframe\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "(df_WOS) = joblib.load(\"df_WOS.pkl\" )\n",
    "print( \"Loaded %d X %d  WOS dataframe\" % (len(df_WOS), len(df_WOS.columns) ))\n",
    "(df_Scopus) = joblib.load(\"df_Scopus.pkl\" )\n",
    "print( \"Loaded %d X %d  Scopus dataframe\" % (len(df_Scopus), len(df_Scopus.columns) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_Scopus, df_WOS], sort = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Df without dupli by doi\n",
    "We start by matching WoS and Scopus publications based on the DOI as it is an unique identifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['low_doi'] = df['doi'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 753 papers without doi\n"
     ]
    }
   ],
   "source": [
    "df_wo_doi = df[df.doi.isnull()]\n",
    "print('There are %d papers without doi' % len(df_wo_doi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4175 different papers with doi\n"
     ]
    }
   ],
   "source": [
    "df_with_doi = df[df.doi.notnull()]\n",
    "df_without_dupli_doi = df_with_doi.groupby(['low_doi']).first().reset_index()\n",
    "print('There are %d different papers with doi' % len(df_without_dupli_doi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4928 papers after removing duplicates based on doi\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat([df_wo_doi, df_without_dupli_doi], sort = False)\n",
    "print('There are %d papers after removing duplicates based on doi' % len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Df without dupli by title\n",
    "We transform the title by \n",
    "* using lower characters\n",
    "* replacing punctuation by white space \n",
    "* replacing double white spaces by one white space  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "string.punctuation =  string.punctuation + '’—☆–'\n",
    "table = str.maketrans(string.punctuation, ' '*len(string.punctuation))\n",
    "titles = df['title'].str.lower().tolist()\n",
    "titles_wo_punct = [title.translate(table) for title in titles]\n",
    "titles_wo_punct_one_white_space = [' '.join(title.split()) for title in titles_wo_punct]\n",
    "df['prepro_title'] = pd.Series(titles_wo_punct_one_white_space,index = df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We order the dataframe by 'low_title' and doi in order to keep papers with doi when there are duplicates (ex : published paper and conference paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.sort_values(by = ['prepro_title','doi'], ascending = [True,True], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4752 papers after removing duplicates based on low title\n"
     ]
    }
   ],
   "source": [
    "df = df.groupby(['prepro_title']).first().reset_index()\n",
    "print('There are %d papers after removing duplicates based on low title' % len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keep papers with abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4740 papers with abstract\n"
     ]
    }
   ],
   "source": [
    "df = df.loc[df.abstract.notnull()]\n",
    "print('There are %d papers with abstract' % len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group by abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4733 papers after removing duplicates based on abstract\n"
     ]
    }
   ],
   "source": [
    "df.sort_values(by = ['abstract','doi'], ascending = [True,True], inplace = True)\n",
    "df = df.groupby(['abstract']).first().reset_index()\n",
    "print('There are %d papers after removing duplicates based on abstract' % (len(df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group by beginning of abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstracts = df['abstract'].str.lower().tolist()\n",
    "abstracts_wo_punct = [abstract.translate(table) for abstract in abstracts]\n",
    "abstracts_wo_punct_one_white_space = [' '.join(abstract.split()) for abstract in abstracts_wo_punct]\n",
    "df['prepro_abs'] = pd.Series(abstracts_wo_punct_one_white_space, index = df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4714 papers after removing duplicates based on first 250 characters of abstract\n"
     ]
    }
   ],
   "source": [
    "df['beg_abs'] = df['prepro_abs'].str[:250]\n",
    "df.sort_values(by = ['beg_abs','doi'], ascending = [True,True], inplace = True)\n",
    "df = df.groupby(['beg_abs']).first().reset_index()\n",
    "\n",
    "print('There are %d papers after removing duplicates based on first 250 characters of abstract' % (len(df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by = ['publication_year','title'], ascending = [False,True], inplace = True)\n",
    "df['d_type'] = df.docu_type.combine_first(df.doc_type)\n",
    "col = ['title','authors','source','doi','d_type','abstract','publication_year','horizon_year','author_keywords','scopus_number','WOS_number','prepro_title']\n",
    "df = df.reindex(columns=col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4714 X 12 dataframe\n"
     ]
    }
   ],
   "source": [
    "print( \"%d X %d dataframe\" % (len(df), len(df.columns) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting papers from Scopus and WOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "932 papers only on Scopus\n",
      "629 papers only on WOS\n",
      "3153 papers on both Scopus and WOS\n"
     ]
    }
   ],
   "source": [
    "df_only_scop = df[df.scopus_number.notnull() & df.WOS_number.isnull()].copy()\n",
    "print(\"%d papers only on Scopus\" % len(df_only_scop) )\n",
    "\n",
    "df_only_WOS = df[df.scopus_number.isnull() & df.WOS_number.notnull()].copy()\n",
    "print(\"%d papers only on WOS\" % len(df_only_WOS) )\n",
    "\n",
    "df_both = df[df.scopus_number.notnull() & df.WOS_number.notnull()].copy()\n",
    "print(\"%d papers on both Scopus and WOS\" % len(df_both) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"fusion_scop_wos.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['df_for_analysis.pkl']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump((df), \"df_for_analysis.pkl\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
